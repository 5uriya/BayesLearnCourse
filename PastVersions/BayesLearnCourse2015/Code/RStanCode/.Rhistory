plot(Xn[,2], type = 'l', ylim = c(1,12), xlab = 'n', ylab = expression(X[n]), main = expression(omega[2]))
d <- c(1,2,4,7)
rep(d,4)
rep(d,1,4)
rep(t(d),4)
rep(d,4,43)
rep(d,4,3)
rep(d,3,4)
?rep
?cbind
?rep
rep(d,3,each=4)
rep(d,3,each=4, byrow)
rep(d,c(1,3))
rep(d,c(4,3))
rep(c(1,3,5,7),4)
matrix(rep(c(1,3,5,7),4))
matrix(rep(c(1,3,5,7),4),4,3)
matrix(rep(c(1,3,5,7),4),4,4)
matrix(rep(d,4),4,4)
matrix(rep(d,nd),nd,nd)
invsigmas <- c(1,3,5,7)
n <- length(invsigmas)
0.9*0.0001/(0.9*0.0001+0.05*(1-0.0001)
)
0.9*0.0001/(0.9*0.0001+0.05*(1-0.0001))
0.9*0.0001/(0.9*0.0001+0.05*(1-0.0001))
0.001796945/0.0001
NormalNonInfoPrior<-function(NDraws,Data){
#####################################################################################
# PURPOSE:   Generates samples from the joint posterior distribution of the parameters in the
#
#    	MODEL: x1,....xn iid Normal(mu,sigma^2) model.
#		PRIOR: p(mu,sigma^2) propto 1/sigma^2
#
#
# INPUT:	NDraw: 		(Scalar)	The number of posterior draws
#		Data:		(n-by-1)	Data vector of n observations
#
# OUTPUT:	PostDraws:	(NDraws-by-2)	Matrix of posterior draws.
#						First column holds draws of mu
#						Second column holds draws of sigma^2
#
# AUTHOR:	Mattias Villani, Sveriges Riksbank and Stockholm University.
#		E-mail: mattias.villani@riksbank.se.
#
# DATE:		2005-04-13
#
######################################################################################
Datamean<-mean(Data)
s2<-var(Data)
n<-length(Data)
PostDraws=matrix(0,NDraws,2)
PostDraws[,1]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,2]<-Datamean+rnorm(NDraws,0,1)*sqrt(PostDraws[,1]/n)
return(PostDraws)
}
Data<-rnorm(100,5,10) 			# Sampling 100 observations from the N(5,10) density##
PostDraws<-NormalNonInfoPrior(100,Data) # Generating 1000 draws from the joint posterior density of mu and sigma^2
hist(PostDraws[,1]) 			# Plotting the histogram of mu-draws
NormalNonInfoPrior
x <- rnorm(100,mean = 3)
hist(x)
NormalNonInfoPrior(1000, x)
PostDraws <- NormalNonInfoPrior(1000, x)
hist(PostDraws[,1],50)
hist(PostDraws[,2],50)
PostDraws <- NormalNonInfoPrior(10000, x)
hist(PostDraws[,1],50)
CV <- PostDraws[,1]/PostDraws[,2]
CV
hist(CV,50)
dpois(0,lambda = 1)
dpois(c(0,1,2,3,4,5,6),lambda = 1)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
LogScaledInvChi2 <- function(x, v, tau){
(v/2)*log(tau^2*v/2) - lgamma(v/2) - (v*tau^2)/(2*x) - (1 + v/2)*log(x)
}
LogVonMisesPDF <- function(x, mu, kappa){
kappa*cos(x-mu) - log(2*pi) - log(besselI(kappa, 0))
}
logPosterior <- function(kappa, x, mu, v, tau){
sum(LogVonMisesPDF(x,mu,kappa)) + sum(LogScaledInvChi2(x, v, tau))
}
windDirections <- c(0.6981317, 5.2883476,5.6897734,4.9741884,5.1661746,5.4803339,0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 5.536801, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
LogScaledInvChi2 <- function(x, v, tau){
(v/2)*log(tau^2*v/2) - lgamma(v/2) - (v*tau^2)/(2*x) - (1 + v/2)*log(x)
}
LogVonMisesPDF <- function(x, mu, kappa){
kappa*cos(x-mu) - log(2*pi) - log(besselI(kappa, 0))
}
logPosterior <- function(kappa, x, mu, v, tau){
sum(LogVonMisesPDF(x,mu,kappa)) + sum(LogScaledInvChi2(x, v, tau))
}
windDirections <- c(0.6981317, 5.2883476,5.6897734,4.9741884,5.1661746,5.4803339,0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 5.536801, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
plot(kappaVals, exp(logPosts -mean(logPosts)), type = "l")
logPosts
windDirections <- c(0.6981317, 5.2883476,5.6897734,4.9741884,5.1661746,5.4803339,0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 5.536801, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
windDirections
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 5.536801, v = 1, tau = 0.001)
}
logPosterior <- function(kappa, x, mu, v, tau){
sum(LogVonMisesPDF(x,mu,kappa)) + sum(LogScaledInvChi2(x, v, tau))
}
LogVonMisesPDF <- function(x, mu, kappa){
kappa*cos(x-mu) - log(2*pi) - log(besselI(kappa, 0))
}
logPosterior <- function(kappa, x, mu, v, tau){
sum(LogVonMisesPDF(x,mu,kappa)) + sum(LogScaledInvChi2(x, v, tau))
}
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 5.536801, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
logPosts
windDirections <- c(0.6981317, 5.2883476, 5.6897734, 4.9741884, 5.1661746, 5.4803339, 0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
windDirections
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 2.39, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
?decp
?dexp
logPosterior <- function(kappa, x, mu, v, tau){
sum(LogVonMisesPDF(x,mu,kappa)) + dexp(kappa,rate=1,log = TRUE)
}
windDirections <- c(0.6981317, 5.2883476, 5.6897734, 4.9741884, 5.1661746, 5.4803339, 0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 2.39, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
#install.packages("CircStats") # Includes function for the MLE of rho and kappa in vonMises.
library(CircStats)
LogScaledInvChi2 <- function(x, v, tau){
(v/2)*log(tau^2*v/2) - lgamma(v/2) - (v*tau^2)/(2*x) - (1 + v/2)*log(x)
}
LogVonMisesPDF <- function(x, mu, kappa){
kappa*cos(x-mu) - log(2*pi) - log(besselI(kappa, 0))
}
logPosterior <- function(kappa, x, mu){
sum(LogVonMisesPDF(x,mu,kappa)) + dexp(kappa,rate=1,log = TRUE)
}
windDirections <- c(0.6981317, 5.2883476, 5.6897734, 4.9741884, 5.1661746, 5.4803339, 0.3490659,
5.3756141, 5.2185345, 5.1661746) - pi
kappaVals <- seq(0.01,10,by = 0.01)
logPosts <- matrix(0,length(kappaVals),1)
count <- 0
for (kappa in kappaVals){
count <- count + 1
logPosts[count] <- logPosterior(kappa, x = windDirections, mu = 2.39, v = 1, tau = 0.001)
}
plot(kappaVals, exp(logPosts), type = "l")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
gamma(59)
gamma(4.3)
gamma(4.3)-4.3*gamma(3.3)
gamma(4.3)-3.3*gamma(3.3)
gamma(4.3+1)-4.3*gamma(4.3)
gamma(1/20)
gamma(1)
gamma(0.9)
gamma(0.3)
gamma(0.1)
gamma(0.001)
gamma(1)
gamma(1/20)
gamma(1/20)/gamma(10000)
gamma(1/20)/gamma(100)
(gamma(1/20)/gamma(100+1/20))/(gamma(100))
(gamma(1/20)/gamma(100+1/20))/(gamma(100))
(gamma(1/20)/gamma(100+1/20))/(1/gamma(100))
1
(gamma(1/20)/gamma(100+1/200))/(1/gamma(100))
(1/gamma(100+1/200))/(1/gamma(100))
(1/gamma(100+1/2))/(1/gamma(100))
alpha <- 1/K,gamma(alpha)
alpha <- 1/K;gamma(alpha)
K<-20;alpha <- 1/K;gamma(alpha)
K<-20;alpha <- 1/K;gamma(alpha)/gamma(m+alpha)
m <- 1000;K<-20;alpha <- 1/K;gamma(alpha)/gamma(m+alpha)
?gammaln
?gamma
lgamma
m <- 1000;K<-20;alpha <- 1/K;lgamma(alpha)/lgamma(m+alpha)
m <- 1000;K<-20;alpha <- 1/K;lgamma(alpha)-lgamma(m+alpha)+lgamma(m)
m <- 1000;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
m <- 10000;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
m <- 100;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
m <- 10000;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
m <- 100000;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
m <- 1000000;K<-20;alpha <- 1/K;c(lgamma(alpha),lgamma(alpha)-lgamma(m+alpha)+lgamma(m))
lgamma(m+alpha)
alpha
lgamma(m+alpha)-lgamma(m)
m<-10;lgamma(m+alpha)-lgamma(m)
m<-100;lgamma(m+alpha)-lgamma(m)
i<-0;for (i in c(10,100,1000,10000,100000,1000000)){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
a <- matrix(NA,6,1)
a
i<-0;for (i in c(10,100,1000,10000,100000,1000000)){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
a
i<-0;for (m in c(10,100,1000,10000,100000,1000000)){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
i<-0;for (m in c(10,100,1000,10000,100000,1000000)){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
a
a <- matrix(NA,6,1)
i<-0;for (m in c(10,100,1000,10000,100000,1000000)){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
a
K
1/K
diff
diff(a)
i<-0;for (m in c(10,100,1000,10000,100000,1000000)+0.5){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
diff(a)
a
m
i<-0;for (m in c(10,100,1000,10000,100000,1000000)+2.5){;i <- i+1;a[i]<-lgamma(m+alpha)-lgamma(m)}
m
diff(a)
rbeta(2,5)
rbeta(10,2,5)
rbeta(10,20,50)
rbeta(10,200,500)
x <- rbeta(100000,a,((1-c)/c)*a)
c <- 0.2;a <-10;x <- rbeta(100000,a,((1-c)/c)*a)
c <- 0.2;a <-10;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x))
c <- 0.2;a <-10;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2)
c <- 0.2;a <-10;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
c <- 0.2;a <-10;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
c <- 0.2;a <-100;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
c <- 0.8;a <-100;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
i<-1;c <- 0.8;a <-log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
log(1)
i<-1;c <- 0.8;a <-5+log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
i<-10;c <- 0.8;a <-5+log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
i<-10;c <- 0.2;a <-5+log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
i<-10;c <- 0.2;a <-5+log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
log(10)
i<-10;c <- 0.2;a <-5;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),var(x),(1-c)*c^2/(a+c))
i<-10;c <- 0.2;a <-5;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),std(x),sqrt((1-c)*c^2/(a+c)))
i<-10;c <- 0.2;a <-5;x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
log(1000)
log(10)
log(50)
log(100)
log(1000)
log(10000)
i<-10;c <- 0.2;a <-log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
i<-100;c <- 0.2;a <-log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
i<-1000;c <- 0.2;a <-log(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
sqrt(100)
c(sqrt(i),log(i))
i <- 100;c(sqrt(i),log(i))
i <- 1000;c(sqrt(i),log(i))
i<-1000;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
i<-10;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)))
i<-10;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)),a,((1-c)/c)*a)
i<-100;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)),a,((1-c)/c)*a)
i<-1000;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)),a,((1-c)/c)*a)
i<-10;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)),a,((1-c)/c)*a)
i<-100;c <- 0.2;a <-sqrt(i);x <- rbeta(100000,a,((1-c)/c)*a);c(mean(x),sd(x),sqrt((1-c)*c^2/(a+c)),a,((1-c)/c)*a)
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
install.packages("geoR") # We need the rinvchisq() function for simulating random draws from the scaled inv chi-square.
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
x
hist(x)
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
# Setting up the plot
xGrid <- seq(min(x)-1*apply(x,2,sd),max(x)+1*apply(x,2,sd),length = 100)
xGridMin <- min(xGrid)
xGridMax <- max(xGrid)
mixDensMean <- rep(0,length(xGrid))
effIterCount <- 0
ylim <- c(0,2*max(hist(x)$intensities))
# Setting up the plot
xGrid <- seq(min(x)-1*apply(x,2,sd),max(x)+1*apply(x,2,sd),length = 100)
xGridMin <- min(xGrid)
xGridMax <- max(xGrid)
mixDensMean <- rep(0,length(xGrid))
effIterCount <- 0
ylim <- c(0,2*max(hist(x)$intensities))
# Setting up the plot
xGrid <- seq(min(x)-1*apply(x,2,sd),max(x)+1*apply(x,2,sd),length = 100)
xGridMin <- min(xGrid)
xGridMax <- max(xGrid)
mixDensMean <- rep(0,length(xGrid))
effIterCount <- 0
ylim <- c(0,2*max(hist(x)$intensities))
hist(x)$intensities)''
hist(x)$intensities)
hist(x)$intensities
hist(x)
hist(x)$
''
2*max(hist(x)$intensities)
a <- hist(x)
a
ylim <- c(0,2*max(hist(x)$density))
ylim
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearning/Code/SimulateDiscreteMarkovChain.R')
source('~/Dropbox/Teaching/BayesLearning/Code/SimulateDiscreteMarkovChain.R')
source('~/Dropbox/Teaching/BayesLearning/Code/SimulateDiscreteMarkovChain.R')
nIter <- 10000 # Number of simulated steps of the Markov chain
P = matrix(c(0.8,0.1,0.1,0.2,0.6,0.2,0.3,0.3,0.4),3,3, byrow=TRUE) # Define a transition matrix
#####   END USER INPUT    #####
install.packages("expm") # To get the matrix power
library(expm)
lineColors = c("red","blue","green","black","yellow")
nStates <- dim(P)[1]
print(P)
# Stationary distribution is normalized left eigenvector of P corresponding to eigenvalue of one.
eigObj <- eigen(t(P))
eigenVect <- eigObj$vector[,eigObj$values == 1]
piStat <- eigenVect/sum(eigenVect)
P
piStat
P
piStat
print(P%^%100)
print(P%^%4)
source('~/Dropbox/Teaching/BayesLearning/Code/RStanCode/Code/1 - presExampleRStan.R')
summary(git1)
summary(fit1)
fit1
fit1<-stan(model_code=stanModel,
data=weightData,
warmup=1000,
iter=2000,
chains=2)
fit1
plot(fit1)
fit1
rm(list=ls())
x = c(1,1,0,0,1,1,1,1,0,1)
n = length(x)
a = 1
b = 1
BernBetaData <- list(n = length(x), x=x, a=1, b=1)
# Model
BernBetaStanModel <- '
data {
int<lower=0> n;
int<lower=0,upper=1> x[n];
real<lower=0> a;
real<lower=0> b;
}
parameters {
real<lower=0,upper=1> p;
}
model {
p ~ beta(a,b);
for (i in 1:n)
x[i] ~ bernoulli(p);
}
'
# Do the fitting of the model
fit1<-stan(model_code=BernBetaStanModel,
data=BernBetaData,
warmup=1000,
iter=2000,
chains=4)
print(fit1,digits_summary=3)
plot(fit1)
rm(list=ls())
dataBernHiarch <- list(x = c(1,1,0,0,1,1,1,1,0,1), n = length(x))
BernBetaHiearchStanModel <- '
data {
int<lower=0> n;
int<lower=0,upper=1> x[n];
}
parameters {
real<lower=0,upper=1> p;
real<lower=0,upper=10> a;
real<lower=0,upper=10> b;
}
model {
for (i in 1:n)
x[i] ~ bernoulli(p);
}
'
# Do the fitting of the model
fit1<-stan(model_code=BernBetaHiearchStanModel,
data=dataBernHiarch,
warmup=nBurnin,
iter=(nBurnin+nIter),
chains=2)
# Data
dataBernHiarch <- list(x = c(1,1,0,0,1,1,1,1,0,1), n = length(x))
rm(list=ls())
library(rstan)
# Data
dataBernHiarch <- list(x = c(1,1,0,0,1,1,1,1,0,1), n = length(x))
dataBernHiarch <- list(x = c(1,1,0,0,1,1,1,1,0,1), 10)
BernBetaHiearchStanModel <- '
data {
int<lower=0> n;
int<lower=0,upper=1> x[n];
}
parameters {
real<lower=0,upper=1> p;
real<lower=0,upper=10> a;
real<lower=0,upper=10> b;
}
model {
for (i in 1:n)
x[i] ~ bernoulli(p);
}
'
# Do the fitting of the model
fit1<-stan(model_code=BernBetaHiearchStanModel,
data=dataBernHiarch,
warmup=nBurnin,
iter=(nBurnin+nIter),
chains=2)
source('~/.active-rstudio-document')
source('~/Dropbox/Teaching/BayesLearning/Code/RStanCode/Code/3 - BernBetaHierarchyRStan.R')
fit1<-stan(model_code=BernBetaHiearchStanModel,
data=dataBernHiarch,
warmup=1000,
iter=2000,
chains=2)
print(fit1,digits_summary=3)
res <- extract(fit1,permuted=FALSE)
# Plot the a:s and b:s
par(mfrow = c(2,2))
hist(res[,1,2], 30, main = 'Posterior of a - first chain') # histogram of draws of a from the first Markov Chain
hist(res[,1,3], 30, main = 'Posterior of b - first chain') # histogram of draws of b from the first Markov Chain
hist(res[,2,2], 30, main = 'Posterior of a - second chain') # histogram of draws of a from the first Markov Chain
hist(res[,2,3], 30, main = 'Posterior of b - second chain') # histogram of draws of b from the first Markov Chain
source('~/Dropbox/Teaching/BayesLearning/Code/RStanCode/Code/4 - LogisticRegRandEffectsRStan.R')
source('~/Dropbox/Teaching/BayesLearning/Code/RStanCode/Code/4 - LogisticRegRandEffectsRStan.R')
plot(fit1)
fit1ParSamples<-extract(fit1,permuted=FALSE)
dim(fit1ParSamples)
# Reuse the model
source('~/Dropbox/Teaching/BayesLearning/Code/RStanCode/Code/5 - RoachesPoissonRStan.R')
install.packages("ggplot2")
#install.packages("ggplot2")
library(ggplot2)
source('~/.active-rstudio-document')
