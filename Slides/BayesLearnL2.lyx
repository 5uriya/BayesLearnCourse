#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass beamer
\begin_preamble
\setcounter{MaxMatrixCols}{10}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathpazo}
\usepackage{hyperref}
\usepackage{multimedia}
\usepackage{xcolor}
\usepackage{colortbl}
\definecolor{RawSienna}{cmyk}{0,0.87,0.82,0.31}
\definecolor{gray97}{cmyk}{0,0,0,0.03}
\definecolor{robinsegg}{cmyk}{0.18,0.04,0,0.07}
\definecolor{cola}{cmyk}{0,0.315,0.35,0.155}

\newenvironment{stepenumerate}{\begin{enumerate}[<+->]}{\end{enumerate}}
\newenvironment{stepitemize}{\begin{itemize}[<+->]}{\end{itemize} }
\newenvironment{stepenumeratewithalert}{\begin{enumerate}[<+-| alert@+>]}{\end{enumerate}}
\newenvironment{stepitemizewithalert}{\begin{itemize}[<+-| alert@+>]}{\end{itemize} }
\usecolortheme[named=RawSienna]{structure}
%\usecolortheme[RGB={205,0,0}]{structure}
\setbeamertemplate{navigation symbols}{}
\useoutertheme{infolines}
\usetheme{default}
\setbeamertemplate{blocks}[shadow=true]
%\setbeamerfont{structure}{shape=\itshape}
\usefonttheme{structuresmallcapsserif}
\setbeamertemplate{background canvas}{
 % \ifnum \thepage>0 \relax % we are on the first page
%\includegraphics[width=\paperwidth,height=\paperheight]{/home/mv/Dropbox/Foton/IconsWallpaper/greyribbonLighter.jpg}
 % \else
 	% No background for page 2 and onwards
 % \fi
}
\end_preamble
\options xcolor=svgnames
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman palatino
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Bayesian Learning
\end_layout

\end_inset

Bayesian Learning - Lecture 2
\end_layout

\begin_layout Author
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Mattias Villani
\end_layout

\end_inset

Mattias Villani
\end_layout

\begin_layout Institute

\series bold
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\series bold
Statistics, LiU
\end_layout

\end_inset

Division of Statistics and Machine Learning
\begin_inset Newline newline
\end_inset

Department of Computer and Information Science
\begin_inset Newline newline
\end_inset

Link√∂ping University 
\end_layout

\begin_layout Date
\begin_inset space \thinspace{}
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Lecture overview
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The Normal model 
\end_layout

\begin_layout Itemize
The Poisson model
\end_layout

\begin_layout Itemize
Conjugate priors
\end_layout

\begin_layout Itemize
Non-informative priors
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal data with known variance - uniform prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Model: 
\begin_inset Formula 
\[
x_{1},...,x_{n}|\theta,\sigma^{2}\overset{iid}{\sim}N(\theta,\sigma^{2}).
\]

\end_inset


\end_layout

\begin_layout Itemize
Prior: 
\begin_inset Formula 
\[
p(\theta)\propto c
\]

\end_inset

 
\end_layout

\begin_layout Itemize
Likelihood 
\begin_inset Formula 
\begin{eqnarray*}
p(x_{1},...,x_{n}|\theta,\sigma^{2}) & = & \Pi_{i=1}^{n}(2\pi\sigma^{2})^{-1/2}\exp\left[-\frac{1}{2\sigma^{2}}(x_{i}-\theta)^{2}\right]\\
 & \propto & \exp\left[-\frac{1}{2(\sigma^{2}/n)}(\theta-\bar{x})^{2}\right].
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Posterior
\begin_inset Formula 
\[
\theta|x_{1},...,x_{n}\sim N(\bar{x},\sigma^{2}/n)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal with known variance - normal prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Prior 
\begin_inset Formula 
\[
\theta\sim N(\mu_{0},\tau_{0}^{2})
\]

\end_inset


\end_layout

\begin_layout Itemize
Posterior
\begin_inset Formula 
\begin{eqnarray*}
p(\theta|x_{1},...,x_{n}) & \propto & p(x_{1},...,x_{n}|\theta,\sigma^{2})p(\theta)\\
 & \propto & N(\theta|\mu_{n},\tau_{n}^{2}),
\end{eqnarray*}

\end_inset

where
\begin_inset Formula 
\[
\frac{1}{\tau_{n}^{2}}=\frac{n}{\sigma^{2}}+\frac{1}{\tau_{0}^{2}},
\]

\end_inset


\begin_inset Formula 
\[
\mu_{n}=w\bar{x}+(1-w)\mu_{0},
\]

\end_inset

and
\begin_inset Formula 
\[
w=\frac{\frac{n}{\sigma^{2}}}{\frac{n}{\sigma^{2}}+\frac{1}{\tau_{0}^{2}}}.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal with known variance - normal prior, cont.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Formula $\theta\sim N(\mu_{0},\tau_{0}^{2})\overset{x_{1},...,x_{n}}{\Longrightarrow}\theta|x\sim N(\mu_{n},\tau_{n}^{2}).$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
\align center
Posterior precision = Data precision + Prior precision
\end_layout

\begin_layout Standard
\align center
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
\align center
Posterior mean =
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula $\frac{\text{Data precision}}{\text{Posterior precision}}$
\end_inset

(Data mean) + 
\begin_inset Formula $\frac{\text{Prior precision}}{\text{Posterior precision}}$
\end_inset

(Prior mean) 
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Canadian wages data
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Data on wages for 
\begin_inset Formula $205$
\end_inset

 Canadian workers.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename CanadianaWagesDataHist.eps
	scale 45

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Canadian wages
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Model
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{1},...,X_{n}|\theta\sim N(\theta,\sigma^{2}),\text{ }\sigma^{2}=0.4
\]

\end_inset


\end_layout

\begin_layout Itemize
Prior
\begin_inset Formula 
\[
\theta\sim N(\mu_{0},\tau_{0}^{2})\text{ }\mu_{0}=12\text{ and }\tau_{0}=10
\]

\end_inset


\end_layout

\begin_layout Itemize
Posterior
\begin_inset Formula 
\[
\theta|x_{1},...,x_{n}\sim N\left(\mu_{n},\tau_{n}^{2}\right),
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
where 
\begin_inset Formula $\mu_{n}=w\bar{x}+(1-w)\mu_{0}$
\end_inset

.
\end_layout

\begin_layout Itemize

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
For the Canadian wage data:
\begin_inset Formula 
\[
w=\frac{\sigma^{-2}n}{\sigma^{-2}n+\tau_{0}^{-2}}=\frac{2.5\cdot205}{2.5\cdot205+1/100}=0.99998.
\]

\end_inset


\begin_inset Formula 
\[
\mu_{n}=w\bar{x}+(1-w)\mu_{0}=0.99998\cdot13.48988+(1-0.99998)\cdot12=13.48985
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\tau_{n}^{2}=\left(2.5\cdot205+1/100\right)^{-1}=0.00195
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Canadian wages data - model fit
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename CanadianaWagesDataHistWithFit.eps
	scale 45

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\size larger
Conjugate priors
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Normal likelihood: Normal prior
\begin_inset Formula $\rightarrow$
\end_inset

Normal posterior.
 (posterior belongs to the same distribution family as prior)
\end_layout

\begin_layout Itemize
Bernoulli likelihood: Beta prior
\begin_inset Formula $\rightarrow$
\end_inset

Beta posterior.
\end_layout

\begin_layout Itemize

\series bold
Conjugate priors
\series default
: A prior is conjugate to a model (likelihood) if the prior and posterior
 belong to the same distributional family.
\end_layout

\begin_layout Itemize

\shape italic
Conjugate priors
\shape default
: Let 
\begin_inset Formula $\mathcal{F}$
\end_inset

 
\begin_inset Formula $=\{p(y|\theta),\theta\in\Theta\}$
\end_inset

 be a class of sampling distributions.
 A family of distributions 
\begin_inset Formula $\mathcal{P}$
\end_inset

 is conjugate for 
\begin_inset Formula $\mathcal{F}$
\end_inset

 if 
\begin_inset Formula 
\[
p(\theta)\in\mathcal{P\Rightarrow}\text{ }p(\theta|x)\in\mathcal{P}
\]

\end_inset

holds for all 
\begin_inset Formula $p(y|\theta)\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Itemize

\series bold
Natural conjugate prior
\series default
: 
\begin_inset Formula $p(\theta)=c\cdot p(y_{1},...,y_{n}|\theta)$
\end_inset

 for some constant 
\begin_inset Formula $c$
\end_inset

, i.e.
 the prior is of the same functional form as the likelihood.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Poisson model
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Likelihood from iid Poisson sample
\shape italic
 
\shape default

\begin_inset Formula $y=(y_{1},...,y_{n})$
\end_inset


\begin_inset Formula 
\[
p(y|\theta)=\left[\prod\nolimits _{i=1}^{n}p(y_{i}|\theta)\right]\propto\theta^{(\sum\nolimits _{i=1}^{n}y_{i})}\exp(-\theta n),
\]

\end_inset

so that the sum of counts 
\begin_inset Formula $\sum\nolimits _{i=1}^{n}y_{i}$
\end_inset

 is a sufficient statistic for 
\begin_inset Formula $\theta.$
\end_inset


\end_layout

\begin_layout Itemize

\shape italic
Natural conjugate prior for Poisson parameter 
\shape default

\begin_inset Formula $\theta$
\end_inset


\begin_inset Formula 
\[
p(\theta)\propto\theta^{\alpha-1}\exp(-\theta\beta)\propto Gamma(\alpha,\beta)
\]

\end_inset

which contains the info: 
\begin_inset Formula $\alpha-1$
\end_inset

 counts in 
\begin_inset Formula $\beta$
\end_inset

 observations.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Poisson model, cont.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\shape italic
Posterior for Poisson parameter 
\shape default

\begin_inset Formula $\theta.$
\end_inset

 Multiplying the poisson likelihood and the Gamma prior gives the posterior
\begin_inset Formula 
\begin{eqnarray*}
p(\theta|y_{1},...,y_{n}) & \propto & \left[\prod\nolimits _{i=1}^{n}p(y_{i}|\theta)\right]p(\theta)\\
 & \propto & \theta^{\sum\nolimits _{i=1}^{n}y_{i}}\exp(-\theta n)\theta^{\alpha-1}\exp(-\theta\beta)\\
 & = & \theta^{\alpha+\sum\nolimits _{i=1}^{n}y_{i}-1}\exp[-\theta(\beta+n)],
\end{eqnarray*}

\end_inset

which is proportional to the 
\begin_inset Formula $Gamma(\alpha+\sum\nolimits _{i=1}^{n}y_{i},\beta+n)$
\end_inset

 distribution.
\end_layout

\begin_layout Itemize
In summary
\begin_inset Formula 
\begin{gather*}
\text{Model: \ }y_{1},...,y_{n}|\theta\overset{iid}{\sim}Po(\theta)\\
\text{Prior: \ }\theta\sim Gamma(\alpha,\beta)\\
\text{Posterior: }\theta|y_{1},...,y_{n}\sim Gamma(\alpha+\sum\nolimits _{i=1}^{n}y_{i},\beta+n)\text{.}
\end{gather*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Poisson example - Number of bomb hits in London
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
n=576\text{, }\sum\nolimits _{i=1}^{n}y_{i}=229\cdot0+211\cdot1+93*2+35*3+7*4+1\cdot5=537.
\]

\end_inset

Average number of hits per region=
\begin_inset Formula $\bar{y}=537/576\approx0.9323.$
\end_inset


\begin_inset Formula 
\[
p(\theta|y)\propto\theta^{\alpha+537-1}\exp[-\theta(\beta+576)]
\]

\end_inset


\begin_inset Formula 
\[
E(\theta|y)=\frac{\alpha+\sum\nolimits _{i=1}^{n}y_{i}}{\beta+n}\approx\bar{y}\approx0.9323,
\]

\end_inset

and
\begin_inset Formula 
\[
SD(\theta|y)=\left(\frac{\alpha+\sum\nolimits _{i=1}^{n}y_{i}}{(\beta+n)^{2}}\right)^{1/2}=\frac{(\alpha+\sum\nolimits _{i=1}^{n}y_{i})^{1/2}}{(\beta+n)}\approx\frac{(537)^{1/2}}{576}\approx0.0402.
\]

\end_inset

 if 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 are small compared to 
\begin_inset Formula $\sum\nolimits _{i=1}^{n}y_{i}$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Poisson bomb hits in London
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename BombHitsPoisson.eps
	scale 42
	rotateAngle 270

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Poisson example - posterior probability intervals
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Bayesian 95% interval: the probability that the unknown parameter 
\begin_inset Formula $\theta$
\end_inset

 lies in the interval is 0.95.
 What a relief! 
\end_layout

\begin_layout Itemize
Approximate 
\begin_inset Formula $95\%$
\end_inset

 credible interval for 
\begin_inset Formula $\theta$
\end_inset

 (for small 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

): 
\begin_inset Formula 
\[
E(\theta|y)\pm1.96\cdot SD(\theta|y)=[0.8535;1.0111]
\]

\end_inset


\end_layout

\begin_layout Itemize
An exact 95% equal-tail interval is 
\begin_inset Formula $[0.8550$
\end_inset

; 
\begin_inset Formula $1.0125]$
\end_inset

 (assuming 
\begin_inset Formula $\alpha=\beta=0$
\end_inset

)
\end_layout

\begin_layout Itemize
Highest Posterior Density (HPD) interval contains the 
\begin_inset Formula $\theta$
\end_inset

 values with highest pdf.
\end_layout

\begin_layout Itemize
An exact Highest Posterior Density (HPD) interval is 
\begin_inset Formula $[0.8525$
\end_inset

; 
\begin_inset Formula $1.0144]$
\end_inset

.
 Obtained numerically, assuming 
\begin_inset Formula $\alpha=\beta=0$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Illustration of different interval types
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename IntervalTypes.png
	lyxscale 40
	scale 27

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Prior elicitation
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The prior should be determined (elicited) by an expert.
 Typically, expert
\begin_inset Formula $\neq$
\end_inset

statistician.
\end_layout

\begin_layout Itemize
Elicit the prior on a quantity that he knows well (maybe log odds 
\begin_inset Formula $\ln\frac{\theta}{1-\theta}$
\end_inset

 when the model is 
\begin_inset Formula $Bern(\theta)$
\end_inset

).
 The statistician can always compute the implied prior on other quantities
 after the elicitation.
\end_layout

\begin_layout Itemize
Elicit the prior by asking the expert probabilistic questions: 
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $E(\theta)=?$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $SD(\theta)=?$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Pr(\theta<c)=?$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $Pr(y>c)=?$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Show the expert some consequences of his elicitated prior.
 If he does not agree with these consequences, iterate the above steps until
 he is happy.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Prior elicitation - AR(p) example
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Autoregressive process or order 
\begin_inset Formula $p$
\end_inset


\begin_inset Formula 
\begin{eqnarray*}
y_{t} & = & \phi_{1}(y_{t-1}-\mu)+...+\phi_{p}(y_{t-p}-\mu)+\varepsilon_{t},\text{ \ensuremath{\varepsilon_{t}\overset{iid}{\sim}N(0,\sigma^{2})}}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Informative prior on the unconditional mean: 
\begin_inset Formula $\mu\sim N(\mu_{0},\tau_{0}^{2})$
\end_inset

.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Usually, 
\begin_inset Formula $\mu_{0}$
\end_inset

 and 
\begin_inset Formula $\tau_{0}^{2}$
\end_inset

 can be specified accurately.
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Noninformative
\begin_inset Quotes erd
\end_inset

 prior on 
\begin_inset Formula $\sigma^{2}$
\end_inset

: 
\begin_inset Formula $p(\sigma^{2})\propto1/\sigma^{2}$
\end_inset


\end_layout

\begin_layout Itemize
Assume for simplicity that all 
\begin_inset Formula $\phi_{i},\text{}i=1,...,p$
\end_inset

 are independent a priori, and 
\begin_inset Formula $\phi_{i}\sim N(\mu_{i},\psi_{i})$
\end_inset


\end_layout

\begin_layout Itemize
Prior on 
\begin_inset Formula $\phi=(\phi_{1},...,\phi_{p})$
\end_inset

 centered on persistent AR(1) process: 
\begin_inset Formula $\mu_{1}=0.8,\text{}\mu_{2}=...=\mu_{p}=0$
\end_inset


\end_layout

\begin_layout Itemize
Prior variance of the 
\begin_inset Formula $\phi_{i}$
\end_inset

 decay towards zeros: 
\begin_inset Formula $Var(\phi_{i})=\frac{c}{i^{\lambda}}$
\end_inset

, so that 
\begin_inset Quotes eld
\end_inset

longer
\begin_inset Quotes erd
\end_inset

 lags are more likely to be zero a priori.
 
\begin_inset Formula $\lambda$
\end_inset

 is a parameter that can be used to determine the rate of decay.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\size larger
Non-informative priors
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
...
 do not exist!
\end_layout

\begin_layout Itemize
...
 may be improper and still lead to proper posterior
\end_layout

\begin_layout Itemize

\series bold
Regularization
\series default
 
\series bold
priors
\end_layout

\begin_layout Itemize
Ideal: Present the posterior distributions for all possible priors.
\end_layout

\begin_layout Itemize
Practical communication - 
\series bold
Reference priors
\series default
.
\end_layout

\begin_layout Itemize
Model the prior in terms of a few 
\series bold
hyperparameters
\series default
.
\begin_inset Formula 
\[
\text{ }
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout

\size larger
Non-informative priors, cont.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Subjective consensus
\series default
: when extreme priors give essentially the same posterior.
\begin_inset Formula 
\[
p(\theta|y)\rightarrow N\left(\hat{\theta},J_{\hat{\theta},\mathbf{x}}^{-1}\right)\text{ for all }p(\theta)\text{ as }n\rightarrow\infty,
\]

\end_inset

where 
\begin_inset Formula $J_{\hat{\theta},\mathbf{x}}$
\end_inset

 is the (observed) information (matrix).
\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Itemize
A common non-informative prior is 
\series bold
Jeffreys' prior 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(\theta)=\left|I_{\theta}\right|^{1/2},
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $I_{\theta}$
\end_inset

 is the Fisher information.
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Jeffreys' prior for Bernoulli trial data
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula $\ $
\end_inset


\begin_inset Formula 
\[
y_{1},...,y_{n}|\theta\overset{iid}{\sim}Bern(\theta).
\]

\end_inset


\begin_inset Formula 
\[
\ln p(y|\theta)=s\ln\theta+f\ln(1-\theta)
\]

\end_inset


\begin_inset Formula 
\[
\frac{d\ln p(y|\theta)}{d\theta}=\frac{s}{\theta}-\frac{f}{(1-\theta)}
\]

\end_inset


\begin_inset Formula 
\[
\frac{d^{2}\ln p(y|\theta)}{d\theta^{2}}=-\frac{s}{\theta^{2}}-\frac{f}{(1-\theta)^{2}}
\]

\end_inset


\begin_inset Formula 
\[
J(\theta)=\frac{E_{y|\theta}(s)}{\theta^{2}}+\frac{E_{y|\theta}(f)}{(1-\theta)^{2}}=\frac{n\theta}{\theta^{2}}+\frac{n(1-\theta)}{(1-\theta)^{2}}=\frac{n}{\theta(1-\theta)}
\]

\end_inset

Thus, the Jeffreys' prior is
\begin_inset Formula 
\[
p(\theta)=\left|J(\theta)\right|^{1/2}\propto\theta^{-1/2}(1-\theta)^{-1/2}\propto Beta(\theta|1/2,1/2).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Jeffreys' prior Binomial vs Negative binomial sampling
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Bernoulli experiment: Perform 
\begin_inset Formula $n$
\end_inset

 independent trials with success probabilty 
\begin_inset Formula $\theta$
\end_inset

 and count the number of successes.
 Here
\begin_inset Formula 
\[
y|\theta\sim Bin(\theta)
\]

\end_inset


\end_layout

\begin_layout Itemize
Inverse Bernoulli experiment: Perform independent trials with success probabilty
 
\begin_inset Formula $\theta$
\end_inset

 until you have observed 
\begin_inset Formula $y$
\end_inset

 successes.
 Here
\begin_inset Formula 
\[
y|\theta\sim NegBin(\theta)
\]

\end_inset


\end_layout

\begin_layout Itemize
Exercise: Suppose you performed both of the two experiments and that in
 both cases you ended up doing 
\begin_inset Formula $n$
\end_inset

 trials and observed 
\begin_inset Formula $y$
\end_inset

 successes.
 Show that the likelihood function conveys the same information on 
\begin_inset Formula $\theta$
\end_inset

 in both cases, but that Jeffreys prior is not the same in both models.
 Is this reasonable?
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Properties of Jeffreys prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Invariant
\series default
 to 1:1 transformations of 
\begin_inset Formula $\theta$
\end_inset

.
 Doesn't matter which parametrization we derive the prior, it always contains
 the same info.
\end_layout

\begin_layout Itemize
Two models with identical likelihood functions (up to constant) can yield
 different Jeffreys' prior.
 Jeffreys' prior does 
\series bold
not
\series default
 respect the likelihood principle.
 The crux of the matter is the expectation with respect to the sampling
 distribution.
\end_layout

\begin_layout Itemize
Jeffreys' prior may be a very complicated (non-conjugate) distribution.
\end_layout

\begin_layout Itemize
Problematic in multivariate problems.
 Dubious results in many standard models.
\end_layout

\end_deeper
\end_body
\end_document
