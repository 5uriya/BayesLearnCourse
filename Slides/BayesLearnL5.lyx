#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass beamer
\begin_preamble
\setcounter{MaxMatrixCols}{10}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathpazo}
\usepackage{hyperref}
\usepackage{multimedia}
\usepackage{xcolor}
\usepackage{colortbl}
\definecolor{RawSienna}{cmyk}{0,0.87,0.82,0.31}
\definecolor{gray97}{cmyk}{0,0,0,0.03}
\definecolor{robinsegg}{cmyk}{0.18,0.04,0,0.07}
\definecolor{cola}{cmyk}{0,0.315,0.35,0.155}

\newenvironment{stepenumerate}{\begin{enumerate}[<+->]}{\end{enumerate}}
\newenvironment{stepitemize}{\begin{itemize}[<+->]}{\end{itemize} }
\newenvironment{stepenumeratewithalert}{\begin{enumerate}[<+-| alert@+>]}{\end{enumerate}}
\newenvironment{stepitemizewithalert}{\begin{itemize}[<+-| alert@+>]}{\end{itemize} }
\usecolortheme[named=RawSienna]{structure}
%\usecolortheme[RGB={205,0,0}]{structure}
\setbeamertemplate{navigation symbols}{}
\useoutertheme{infolines}
\usetheme{default}
\setbeamertemplate{blocks}[shadow=true]
%\setbeamerfont{structure}{shape=\itshape}
\usefonttheme{structuresmallcapsserif}
\setbeamertemplate{background canvas}{
 % \ifnum \thepage>0 \relax % we are on the first page
%\includegraphics[width=\paperwidth,height=\paperheight]{/home/mv/Dropbox/Foton/IconsWallpaper/greyribbonLighter.jpg}
 % \else
 	% No background for page 2 and onwards
 % \fi
}
\end_preamble
\options xcolor=svgnames, handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman palatino
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Bayesian Learning
\end_layout

\end_inset

Bayesian Learning - Lecture 5 
\end_layout

\begin_layout Author
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Mattias Villani
\end_layout

\end_inset

Mattias Villani
\end_layout

\begin_layout Institute

\series bold
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\series bold
Statistics, LiU
\end_layout

\end_inset

Division of Statistics and Machine Learning
\begin_inset Newline newline
\end_inset

Department of Computer and Information Science
\begin_inset Newline newline
\end_inset

LinkÃ¶ping University 
\end_layout

\begin_layout Date
\begin_inset space \thinspace{}
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Lecture overview
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Normal model with conjugate prior
\end_layout

\begin_layout Itemize
The linear regression model
\end_layout

\begin_layout Itemize
Regression with binary response
\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal model - conjugate prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Model
\begin_inset Formula 
\[
y_{1},...,y_{n}|\theta,\sigma^{2}\overset{iid}{\sim}N(\theta,\sigma^{2})
\]

\end_inset


\end_layout

\begin_layout Itemize
Conjugate prior
\begin_inset Formula 
\begin{gather*}
\theta|\sigma^{2}\sim N\left(\mu_{0},\frac{\sigma^{2}}{\kappa_{0}}\right)\\
\sigma^{2}\sim Inv\text{-}\chi^{2}(\nu_{0},\sigma_{0}^{2})
\end{gather*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal model with conjugate prior, cont.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Posterior 
\begin_inset Formula 
\begin{gather*}
\theta|y,\sigma^{2}\sim N\left(\mu_{n},\frac{\sigma^{2}}{\kappa_{n}}\right)\\
\sigma^{2}|y\sim Inv\text{-}\chi^{2}(\nu_{n},\sigma_{n}^{2}).
\end{gather*}

\end_inset

where
\begin_inset Formula 
\begin{eqnarray*}
\mu_{n} & = & \frac{\kappa_{0}}{\kappa_{0}+n}\mu_{0}+\frac{n}{\kappa_{0}+n}\bar{y}\\
\kappa_{n} & = & \kappa_{0}+n\\
\nu_{n} & = & \nu_{0}+n\\
\nu_{n}\sigma_{n}^{2} & = & \nu_{0}\sigma_{0}^{2}+(n-1)s^{2}+\frac{\kappa_{0}n}{\kappa_{0}+n}(\bar{y}-\mu_{0})^{2}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Marginal posterior
\begin_inset Formula 
\begin{gather*}
\theta\sim t_{\nu_{n}}\left(\mu_{n},\sigma_{n}^{2}/\kappa_{n}\right)
\end{gather*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The Linear Regression Model 
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The ordinary linear regression model:
\begin_inset Formula 
\begin{eqnarray*}
y_{i} & = & \beta_{1}x_{i1}+\beta_{2}x_{i2}+...+\beta_{k}x_{ik}+\varepsilon_{i}\\
 &  & \varepsilon_{i}\overset{iid}{\sim}N(0,\sigma^{2}).
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Parameters 
\begin_inset Formula $\theta=(\beta_{1},\beta_{2},...,\beta_{k},\sigma^{2})$
\end_inset

.
\end_layout

\begin_layout Itemize
Assumptions:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $E(y_{i})=\beta_{1}x_{i1}+\beta_{2}x_{i2}+...+\beta_{k}x_{ik}$
\end_inset

 (linear function)
\end_layout

\begin_layout Itemize
\begin_inset Formula $Var(y_{i})=\sigma^{2}$
\end_inset

 (homoscedasticity)
\end_layout

\begin_layout Itemize
\begin_inset Formula $Corr(y_{i},y_{j}|X)=0$
\end_inset

, 
\begin_inset Formula $i\neq j$
\end_inset

.
\end_layout

\begin_layout Itemize
Normality of 
\begin_inset Formula $\varepsilon_{i}$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear regression in matrix form
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The linear regression model in matrix form
\begin_inset Formula 
\[
\underset{(n\times1)}{y}=\underset{(n\times k)(k\times1)}{X\beta}+\underset{(n\times1)}{\varepsilon}
\]

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
y & = & \left(\begin{array}{c}
y_{1}\\
\vdots\\
y_{n}
\end{array}\right),\text{ }\beta=\left(\begin{array}{c}
\beta_{1}\\
\vdots\\
\beta_{k}
\end{array}\right),\text{ }\varepsilon=\left(\begin{array}{c}
\varepsilon_{1}\\
\vdots\\
\varepsilon_{n}
\end{array}\right)\\
X & = & \left(\begin{array}{c}
x_{1}^{\prime}\\
\vdots\\
x_{n}^{\prime}
\end{array}\right)=\left(\begin{array}{ccc}
x_{11} & \cdots & x_{1k}\\
\vdots & \ddots & \vdots\\
x_{n1} & \cdots & x_{nk}
\end{array}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Usually 
\begin_inset Formula $x_{i1}=1$
\end_inset

, for all 
\begin_inset Formula $i$
\end_inset

.
 
\begin_inset Formula $\beta_{1}$
\end_inset

 is the intercept.
\end_layout

\begin_layout Itemize
Likelihood for the full sample
\begin_inset Formula 
\[
y|\beta,\sigma^{2},X\sim N(X\beta,\sigma^{2}I_{n})
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Posterior for the uniform prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Standard non-informative prior: uniform on (
\begin_inset Formula $\beta,\log\sigma^{2}$
\end_inset

)
\begin_inset Formula 
\[
p(\beta,\sigma^{2})\propto\sigma^{-2}
\]

\end_inset


\end_layout

\begin_layout Itemize
Joint posterior of 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

:
\begin_inset Formula 
\[
p(\beta,\sigma^{2}|y)=p(\beta|\sigma^{2},y)p(\sigma^{2}|y).
\]

\end_inset


\end_layout

\begin_layout Itemize
Conditional posterior of 
\begin_inset Formula $\beta:$
\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\beta|\sigma^{2},y & \sim & N\left[\hat{\beta},\sigma^{2}(X^{\prime}X)^{-1}\right]\\
\hat{\beta} & = & (X^{\prime}X)^{-1}X^{\prime}y
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Marginal posterior of 
\begin_inset Formula $\sigma^{2}:$
\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\sigma^{2}|y & \sim & Inv\text{-}\chi^{2}(n-k,s^{2})\\
s^{2} & = & \frac{1}{n-k}(y-X\hat{\beta})^{\prime}(y-X\hat{\beta}).
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Posterior for the uniform prior, cont.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Marginal posterior of 
\begin_inset Formula $\beta:$
\end_inset


\begin_inset Formula 
\[
\beta|y\sim t_{n-k}\left[\hat{\beta},s^{2}(X^{\prime}X)^{-1}\right]
\]

\end_inset

which is proper if 
\begin_inset Formula $n>k$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 has full column rank.
\end_layout

\begin_layout Itemize
Simulate from the joint posterior by iteratively simulating from 
\begin_inset Formula $p(\sigma^{2}|y)$
\end_inset

 and 
\begin_inset Formula $p(\beta|\sigma^{2},y)$
\end_inset

.
\end_layout

\begin_layout Itemize
Predictive distribution of response 
\begin_inset Formula $\tilde{y}$
\end_inset

 with known predictors 
\begin_inset Formula $\tilde{x}$
\end_inset

 
\begin_inset Formula 
\[
\tilde{y}|y,\tilde{x}\sim t_{n-k}\left[\tilde{x}'\hat{\beta},s^{2}(1+\tilde{x}'(X'X)\tilde{x})^{-1}\right]
\]

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\text{Predictive Precision} & = & s^{-2}+\tilde{x}'(s^{-2}X'X)\tilde{x}\\
 & = & \varepsilon\text{-Precision + }\tilde{x}'(\text{Posterior Precision of }\beta)\tilde{x}.
\end{eqnarray*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear regression - conjugate prior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Joint prior for 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2} & \sim N\left(\mu_{0},\sigma^{2}\Omega_{0}^{-1}\right)\\
\sigma^{2} & \sim Inv-\chi^{2}\left(\nu_{0},\sigma_{0}^{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Posterior
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2} & \sim N\left[\mu_{n},\sigma^{2}\Omega_{n}^{-1}\right]\\
\sigma^{2} & \sim Inv-\chi^{2}\left(\nu_{n},\sigma_{n}^{2}\right)
\end{align*}

\end_inset

 
\begin_inset Formula 
\begin{align*}
\mu_{n} & =\left(X'X+\Omega_{0}\right)^{-1}\left(X'X\hat{\beta}+\Omega_{0}\mu_{0}\right)\\
\Omega_{n} & =X'X+\Omega_{0}\\
\nu_{n} & =\nu_{0}+n\\
\nu_{n}\sigma_{n}^{2} & =\nu_{0}\sigma_{0}^{2}+\left(y'y+\mu_{0}'\Omega_{0}\mu_{0}-\mu_{n}'\Omega_{n}\mu_{n}\right)
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Regression with binary response
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Response is assumed to be 
\series bold
binary
\series default
 (0-1).
\end_layout

\begin_layout Itemize
Example: Predicting whether or not an e-mail is good (
\begin_inset Formula $y=1$
\end_inset

) or spam (
\begin_inset Formula $y=0$
\end_inset

).
 Covariates: mean word length, proportion of 
\begin_inset Formula $\$$
\end_inset

-symbols.
\end_layout

\begin_layout Itemize

\series bold
Logistic regression
\series default

\begin_inset Formula 
\[
\Pr(y_{i}=1\text{ }|\text{ }x_{i})=\frac{\exp(x_{i}^{\prime}\beta)}{1+\exp(x_{i}^{\prime}\beta)}.
\]

\end_inset

Likelihood:
\begin_inset Formula 
\[
p(y|X,\beta)=\prod\nolimits _{i=1}^{n}\frac{[\exp(x_{i}^{\prime}\beta)]^{y_{i}}}{1+\exp(x_{i}^{\prime}\beta)}.
\]

\end_inset

Posterior is non-standard, but in most situation can be approximated well
 by a normal distribution.
 Optimization.
\end_layout

\begin_layout Itemize
Alternative: 
\series bold
Probit regression
\series default

\begin_inset Formula 
\[
Pr(y_{i}=1|x_{i})=\Phi(x_{i}^{'}\beta)
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Asymptotic posterior - Heuristics
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Taylor expansion of log-posterior around the posterior mode 
\begin_inset Formula $\theta=\tilde{\theta}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\ln p(\theta|y) & =\ln p(\tilde{\theta}|y)+\frac{\partial\ln p(\theta|y)}{\partial\theta}|_{\theta=\tilde{\theta}}(\theta-\tilde{\theta})\\
 & +\frac{1}{2!}\frac{\partial^{2}\ln p(\theta|y)}{\partial\theta^{2}}|_{\theta=\tilde{\theta}}(\theta-\tilde{\theta})^{2}+...
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
From the definition of the posterior mode:
\begin_inset Formula 
\[
\frac{\partial\ln p(\theta|y)}{\partial\theta}|_{\theta=\tilde{\theta}}=0
\]

\end_inset


\end_layout

\begin_layout Itemize
So, in large samples (where we can ignore higher order terms):
\begin_inset Formula 
\begin{align*}
\ln p(\theta|y) & \approx\ln p(\tilde{\theta}|y)-\frac{1}{2}H_{\mathbf{y}}(\tilde{\theta})(\theta-\tilde{\theta})^{2}
\end{align*}

\end_inset

where 
\begin_inset Formula $H_{\mathbf{y}}(\tilde{\theta})=-\frac{\partial^{2}\ln p(\theta|y)}{\partial\theta^{2}}|_{\theta=\tilde{\theta}}$
\end_inset

.
\end_layout

\begin_layout Itemize
Approximate posterior
\begin_inset Formula 
\[
\theta|y\sim N\left[\tilde{\theta},H_{\mathbf{y}}^{-1}(\tilde{\theta})\right]
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Separator

\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal approximation of posterior
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
If posterior is approximately normal, sufficient to find the posterior mode
 and (inverse) information matrix.
\end_layout

\begin_layout Itemize
Standard (e.g.
 gradient-based) optimization routines may be used.
 (optim.r).
 Input: an expression proportional to 
\begin_inset Formula $p(\theta|y)$
\end_inset

 and initial values.
 Output: optimum (posterior) mode and Hessian matrix (minus observed information
).
\end_layout

\begin_layout Itemize
Joint posterior 
\begin_inset Formula $p(\theta_{1},\theta_{2}|y)$
\end_inset

 may not be be close to normal, but perhaps 
\begin_inset Formula $p(\theta_{2}|\theta_{1},y)$
\end_inset

 and 
\begin_inset Formula $p(\theta_{2}|y)$
\end_inset

 are.
\end_layout

\begin_layout Itemize
Even if the posterior of 
\begin_inset Formula $\theta$
\end_inset

 is approx normal, interesting functions of 
\begin_inset Formula $\theta$
\end_inset

 may not be (e.g.
 predictions).
 Still need to resort to numerical methods.
\end_layout

\begin_layout Itemize
Re-parametrization 
\begin_inset Formula $\phi=g(\theta)$
\end_inset

 may improve normal approximation.
 If 
\begin_inset Formula $\theta\geq0$
\end_inset

 use logs.
 If 
\begin_inset Formula $0\leq\theta\leq1$
\end_inset

, use 
\begin_inset Formula $\mathrm{Logit}(\theta)=\ln[\theta/(1-\theta)]$
\end_inset

.
\end_layout

\begin_layout Itemize
Posterior mode and inverse Hessian can be used to approximate the posterior
 with a student-t density.
\end_layout

\end_deeper
\end_body
\end_document
