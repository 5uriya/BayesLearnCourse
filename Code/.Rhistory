View(data)
save(file = "finney.dat", list = list(data))
save(file = "finney.dat", list = list(data=data))
?save
save(data, file = "finney.dat")
save(data, file = "finney.dat", ascii = TRUE)
getwd()
library(MASS)
write.matrix(data, file = "finney.dat")
names(data) <- c("condition", "constant","airVolume", "airRate")
write.matrix(data, file = "finney.dat")
data
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
hist(postBeta[,1])
nIter <- 5000        # Number of MCMC iterations
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
density(postBeta[,1])
a <- density(postBeta[,1])
plot(a$x,a$y)
par(mfrow = c(2,2))
source('~/.active-rstudio-document')
par(mfrow = c(2,2))
for (j in 1:3){
densEst <- density(postBeta[,1])
plot(densEst$x,densEst$y)
}
par(mfrow = c(2,2))
for (j in 1:3){
densEst <- density(postBeta[,1])
plot(densEst$x,densEst$y, type = "l")
}
par(mfrow = c(2,2))
for (j in 1:3){
densEst <- density(postBeta[,j])
plot(densEst$x,densEst$y, type = "l")
}
dataFile <- "/home/mv/Dropbox/Teaching/BayesLearn2012/Code/SpamReduced.dat"
chooseCov <- c(1:3) # Here we choose which covariates to include in the model
tau <- 1000            # Prior scaling factor such that Prior Covariance = (tau^2)*I
nIter <- 5000        # Number of MCMC iterations
prcBurnin <- 10      # Percentage of nIter draws that are discarded before the nIter draws.
###########     END USER INPUT    ################
# install.packages("mvtnorm") # Loading a package that contains the multivariate normal pdf
# install.packages("msm")     # Loading a package that contains the truncated normal distribution
library("mvtnorm") # This command reads the mvtnorm package into R's memory. NOW we can use dmvnorm function.
library(msm)
# Preliminaries
nBurnin <- round(nIter*prcBurnin/100)
nIter <- nIter + nBurnin
# Loading data from file
Data<-read.table(dataFile, header=TRUE)  # Spam data from Hastie et al.
y <- as.vector(Data[,1]) # Data from the read.table function is a data frame. Let's convert y and X to vector and matrix.
y
size(Dat)
size(Data)
dim(Data)
covNames
X <- as.matrix(Data[,2:17])
covNames <- names(Data)[2:length(names(Data))]
covNames
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
dim(postBeta)
nPara
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
?ACF
?acf
ACF[j] <- 1+2*sum(acf(postBeta[,j], plot = FALSE)$acf[-1])
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
geyser
hist(geyser)
hist(geyser$waiting)
hist(geyser$duration)
hist(geyser$waiting)
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
hist(geyser$waiting)
hist(geyser$duration)
plot(cumsum(rcauchy(100000))/100000)
plot(cumsum(rcauchy(100000))/100000, type ="l")
plot(cumsum(rcauchy(100000))/100000, type ="l")
plot(cumsum(1/rcauchy(100000))/100000, type ="l")
plot(cumsum(1/rcauchy(100000))/100000, type ="l")
plot(cumsum(1/rcauchy(100000)^2)/100000, type ="l")
library(geoR)
##########    BEGIN USER INPUT #################
# Data options
#rawData <- read.table('/home/mv/Dropbox/Teaching/BayesLearn2012/Code/CanadianWages.dat', header = TRUE)
#x <- as.matrix(rawData['logWage'])
rawData <- geyser
x <- as.matrix(rawData['duration'])
hist(x)
hist(x)
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/NormalMixtureGibbs.R')
nIter <- 10000 # Number of simulated steps of the Markov chain
P = matrix(c(0.8,0.1,0.1,0.2,0.6,0.2,0.3,0.3,0.4),3,3, byrow=TRUE) # Define a transition matrix
P
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
nIter
x[1:10]
x[1:30]
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
sum(x==1)/10000
install.packages("R.matlab")
library(R.matlab)
data <- readMat(file = '/home/mv/Desktop/hand_movements_left.mat')
?readMat
data <- readMat(con = '/home/mv/Desktop/hand_movements_left.mat')
install.packages("R.utils")
data <- readMat(con = '/home/mv/Desktop/hand_movements_left.mat')
data
data$vol.exp
is.data.frame(data$vol.exp)
typeof(data$vol.exp)
class(data$vol.exp)
dim(data$vol.exp)
plot(data$vol.exp[1,1,1,])
plot(data$vol.exp[1,1,1,], type = "l")
install.packages("arima")
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/SimulateDiscreteMarkovChain.R')
?rnorm
source('~/Downloads/LottaJarvstratJonasErlandsson3 (1).R')
source('~/.active-rstudio-document')
source('~/Dropbox/Teaching/BayesLearn2012/Code/LottaJarvstratJonasErlandsson3 (1).R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/LottaJarvstratJonasErlandsson3 (1).R')
setwd('/home/mv/Dropbox/Teaching/BayesLearn2012/Code/')
source('~/Dropbox/Teaching/BayesLearn2012/Code/LottaJarvstratJonasErlandsson3 (1).R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/LottaJarvstratJonasErlandsson3 (1).R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/LottaJarvstratJonasErlandsson3 (1).R')
beta2
mean(beta2)
colMeans(beta2)
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
diag(1,3,3)
diag(4)
rtnorm(1,mean=X1%*%beta[i,], sd=Vect1, lower=0, upper=Inf )
rtnorm(1,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
rtnorm(2,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
rtnorm(5,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
rtnorm(3,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
rtnorm(3,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
rtnorm(3,mean=c(4,5,10), sd=1, lower=0, upper=Inf )
source('~/.active-rstudio-document')
colMeans(beta2)
Probit_Gibbs<-function(y, X, nIter=1000){
beta <- matrix(NA, nIter, ncol(X))
tau<-10
u <- rep(0, length(y))
omega0<-solve(tau^2*diag(1,ncol(X), ncol(X)))
tXX<-t(X)%*%X
stXX<-solve(tXX)
Vect1<-rep(1, length(y[y==1]))
Vect0<-rep(1, length(y[y==0]))
X1 <- X[y==1, ]
X0 <- X[y==0, ]
for(i in 1:nIter){
#step Beta
betaHat <- as.numeric(stXX%*%t(X)%*%u)
myN<-solve(tXX+omega0)%*%(tXX%*%betaHat)
omegaN<-tXX+omega0
beta[i,]<-rmvnorm(1, myN, solve(omegaN))
#step u
u[y==1]<-rtnorm(length(Vect1),mean=X1%*%beta[i,], sd=Vect1, lower=0, upper=Inf )
u[y==0]<-rtnorm(length(Vect0),mean=X0%*%beta[i,], sd=Vect0, lower=-Inf, upper=0 )
}
return(beta)
}
beta2<-Probit_Gibbs(ySpam, XSpam, 100)
colMeans(beta2)
colMeans(beta2)
source('~/Dropbox/Teaching/BayesLearn2012/Code/ProbitReg.R')
source('~/.active-rstudio-document')
myImagePlot
myImagePlot(matrix(rnorm(25),5,5))
myImagePlot(matrix(rnorm(25)*100,5,5))
myImagePlot(matrix(rnorm(100*100)*1,100,100))
library(R.matlab)
data <- readMat(con = '/home/mv/Desktop/hand_movements_left.mat')
bold <- data$vol.exp
dim(bold)
mapply(bold,4)
apply(bold,mean,4)
?mean
is.array(bold)
?apply
apply(bold, 4, mean)
dim(apply(bold, 4, mean))
as.matrix((apply(bold, 4, mean)))
dim(as.matrix((apply(bold, 4, mean))))
dim(apply(bold, c(1,2), mean))
averageBold <- apply(bold, c(1,2), mean)
myImagePlot(averageBold)
?myImagePlot
install.packages("ClassDiscovery")
install.packages("colorschemes")
install.packages("ClassDiscovery")
source("http://bioinformatics.mdanderson.org/OOMPA/oompaLite.R")
oompaLite()
image(averageBold, col=jetColors(64))
oompainstall()
image(averageBold, col=jetColors(64))
library(ClassDiscovery)
jet.colors <-
colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000"))
jet.colors
jet.colors(0.5)
jet.colors(0.2)
jet.colors <-
colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000"))
?image
require(grDevices) # for colours
x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
image(z = z <- cos(r^2)*exp(-r/6), col=gray((0:32)/32))
image(z, axes = FALSE, main = "Math can be beautiful ...",
xlab = expression(cos(r^2) * e^{-r/6}))
contour(z, add = TRUE, drawlabels = FALSE)
# Volcano data visualized as matrix. Need to transpose and flip
# matrix horizontally.
image(t(volcano)[ncol(volcano):1,])
# A prettier display of the volcano
x <- 10*(1:nrow(volcano))
y <- 10*(1:ncol(volcano))
image(x, y, volcano, col = terrain.colors(100), axes = FALSE)
contour(x, y, volcano, levels = seq(90, 200, by = 5),
add = TRUE, col = "peru")
axis(1, at = seq(100, 800, by = 100))
axis(2, at = seq(100, 600, by = 100))
box()
title(main = "Maunga Whau Volcano", font.main = 4)
require(grDevices) # for colours
x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
image(z = z <- cos(r^2)*exp(-r/6), col=gray((0:32)/32))
image(z, axes = FALSE, main = "Math can be beautiful ...",
xlab = expression(cos(r^2) * e^{-r/6}))
contour(z, add = TRUE, drawlabels = FALSE)
image(t(volcano)[ncol(volcano):1,])
image(x, y, volcano, col = terrain.colors(100), axes = FALSE)
image(bold)
dim(bold)
image(bold)
image(x = 1:64, y = 1:64, z= bold)
is.matrix(bold)
image(x = 1:64, y = 1:64, z= as.matrix(bold))
size(bold)
dim(bold)
is.matrix(averageBold)
is.matrix(averageBold)
image(x = 1:64, y = 1:64, z= averageBold)
image(x, y, volcano, col = terrain.colors(100), axes = FALSE)
image(x = 1:64, y = 1:64, z= averageBold, col = terrain.colors(100), axes = FALSE)
image(x = 1:64, y = 1:64, z= averageBold, col = jet.colors(100), axes = FALSE)
class(jet.colors)
image(x = 1:64, y = 1:64, z= t(averageBold), col = jet.colors(100), axes = FALSE)
image(x = 1:64, y = 1:64, z= t(averageBold), col = jet.colors(100), axes = FALSE, xlab ="", ylab="")
image(x = 1:64, y = 1:64, z= t(averageBold), col = jet.colors(100), xlab ="", ylab="")
?colorbar
?image
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(20), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(50), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(200), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(1), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(10), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="", legend.only=TRUE)
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="" ,legend.lab = "Density")
image(z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image.plot(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
install.packages("fields")
image.plot(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
#install.packages("R.matlab")
library(R.matlab)
data <- readMat(con = '/home/mv/Desktop/hand_movements_left.mat')
bold <- data$vol.exp
averageBold <- apply(bold, c(1,2), mean)
data <- readMat(con = '/home/mv/Desktop/hand_movements_left.mat')
bold <- data$vol.exp
averageBold <- apply(bold, c(1,2), mean)
# Creating Matlab-like color scheme for beautiful heat maps
jet.colors <- colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000"))
# Plotting the heat map
image.plot(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
# Creating Matlab-like color scheme for beautiful heat maps
jet.colors <- colorRampPalette(c("#00007F","blue","#007FFF","cyan","#7FFF7F","yellow","#FF7F00","red","#7F0000"))
# Plotting the heat map
image(x = 1:64, y = 1:64, z = t(averageBold), col = jet.colors(100), xlab ="", ylab="")
bold[1,1,1,]
mean(bold[1,1,1,])
sd(bold[1,1,1,])
25/7.2
image(x = 1:64, y = 1:64, z = t(bold[,,1,1], col = jet.colors(100), xlab ="", ylab="")
)
image(x = 1:64, y = 1:64, z = t(bold[,,1,1]), col = jet.colors(100), xlab ="", ylab="")
for (tr in 1:22){
image(x = 1:64, y = 1:64, z = t(bold[,,1,tr]), col = jet.colors(100), xlab ="", ylab="")
}
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
25/7.2
mean(bold[1,1,1,])/sd(bold[1,1,1,])
for (i in 1:64){for (j in 1:64){mean(bold[i,j,1,])/sd(bold[i,j,1,])}}
for (i in 1:64){for (j in 1:64){a[i,j] <- mean(bold[i,j,1,])/sd(bold[i,j,1,])}}
SN <- matrix(NA,64,64);for (i in 1:64){for (j in 1:64){SN[i,j] <- mean(bold[i,j,1,])/sd(bold[i,j,1,])}}
SN
SNR <- matrix(NA,64,64)
for (i in 1:64){
for (j in 1:64){
SNR[i,j] <- mean(bold[i,j,1,])/sd(bold[i,j,1,])
}
}
image(x = 1:64, y = 1:64, z = t(SNR), col = jet.colors(100), xlab ="", ylab="", main = paste("TR = ", tr))
par(mfrow = c(25,25))
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,1,tr]), col = jet.colors(100), xlab ="", ylab="", main = paste("TR = ", tr))
Sys.sleep(0.1)
}
}
source('~/.active-rstudio-document')
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="", main = paste("Slice = ",slice,TR = ", tr))
Sys.sleep(0.1)
}
}
}
''
''
}
}
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
dev.off()
par(mfrow = c(5,4))
for (slice in 1:20){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
for (slice in 1:22){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
for (slice in 1:22){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
source('~/Dropbox/Projects/NeuroStats/Rice/Code/AndersDataImages.R')
source('~/Dropbox/Projects/NeuroStats/Rice/Code/AndersDataImages.R')
source('~/Dropbox/Projects/NeuroStats/Rice/Code/AndersDataImages.R')
for (slice in 1:22){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.01)
}
}
source('~/.active-rstudio-document')
for (slice in 1:22){
for (tr in 1:79){
image(x = 1:64, y = 1:64, z = t(bold[,,slice,tr]), col = jet.colors(100), xlab ="", ylab="",
main = paste("Slice = ", slice, "TR = ", tr))
Sys.sleep(0.1)
}
}
SNR <- matrix(NA,64,64,22)
dim(SNR)
SNR <- array(NA,64,64,22)
matrix
?matrix
?list
list(NA,4,1)
list(NA,NA,NA)
?list
vector("list", 5)
SNR <- vector("list", 22)
for (slice in 1:22){
SNR[slice] <- matrix(NA,64,64)
for (i in 1:64){
for (j in 1:64){
SNR[slice][i,j] <- mean(bold[i,j,1,])/sd(bold[i,j,1,])
}
}
}
SNR
SNR[1] <- matrix(NA,64,64)
SNR[[1]] <- matrix(NA,64,64)
SNR <- vector("list", 22)
for (slice in 1:22){
SNR[[slice]] <- matrix(NA,64,64)
for (i in 1:64){
for (j in 1:64){
SNR[[slice]][i,j] <- mean(bold[i,j,1,])/sd(bold[i,j,1,])
}
}
}
SNR <- vector("list", 22)
for (slice in 1:22){
SNR[[slice]] <- matrix(NA,64,64)
for (i in 1:64){
for (j in 1:64){
SNR[[slice]][i,j] <- mean(bold[i,j,slice,])/sd(bold[i,j,slice,])
}
}
}
SNR
par(mfrow = c(4,5))
for (slice in 1:20){
image(x = 1:64, y = 1:64, z = t(SNR[[slice]]), col = jet.colors(100), xlab ="", ylab="", main = paste("TR = ", tr))
}
# Author: Mattias Villani, Statistics, Linkoping University, Sweden. e-mail: mattias.villani@liu.se
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
library(manipulate)
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
tau0
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Teaching/BayesLearning/HT2013/Code/PriorPosteriorManipNormal.R')
source('~/Dropbox/Seminars/Ericsson2014/PriorPosteriorManipNormal.R')
source('~/Dropbox/Seminars/Ericsson2014/PriorPosteriorManipNormal.R')
source('~/Dropbox/Seminars/Ericsson2014/PriorPosteriorManipNormal.R')
